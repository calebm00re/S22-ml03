{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab Three: Extending Logistic Regression\n",
    "## Caleb Moore, Blake Gebhardt, Christian Gould\n",
    "dataset: https://www.kaggle.com/datasets/open-powerlifting/powerlifting-database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import svm\n",
    "from sklearn import datasets\n",
    "from numpy.linalg import pinv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<script>\n",
       "code_show_err=false; \n",
       "function code_toggle_err() {\n",
       " if (code_show_err){\n",
       " $('div.output_stderr').hide();\n",
       " } else {\n",
       " $('div.output_stderr').show();\n",
       " }\n",
       " code_show_err = !code_show_err\n",
       "} \n",
       "$( document ).ready(code_toggle_err);\n",
       "</script>\n",
       "To toggle on/off output_stderr, click <a href=\"javascript:code_toggle_err()\">here</a>."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Notebook setup\n",
    "from IPython.display import HTML\n",
    "HTML('''<script>\n",
    "code_show_err=false; \n",
    "function code_toggle_err() {\n",
    " if (code_show_err){\n",
    " $('div.output_stderr').hide();\n",
    " } else {\n",
    " $('div.output_stderr').show();\n",
    " }\n",
    " code_show_err = !code_show_err\n",
    "} \n",
    "$( document ).ready(code_toggle_err);\n",
    "</script>\n",
    "To toggle on/off output_stderr, click <a href=\"javascript:code_toggle_err()\">here</a>.''')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparation and Overview (3 points total)\n",
    "* [2 points] Explain the task and what business-case or use-case it is designed to solve (or designed to investigate). Detail exactly what the classification task is and what parties would be interested in the results. For example, would the model be deployed or used mostly for offline analysis? As in previous labs, also detail how good the classifier needs to perform in order to be useful."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Background\n",
    "### Where did our data come from?\n",
    "* Our data came from the Open Powerlifting Databse. They are trying to create a database of powerlifting competitions for the public domain. The dataset that we are using here is a snapshot of what the database looked like as of April 2019. Powerlifting is a sport in which competitors compete to lift the most weight for their class in three separate barbell lifts: the Squat, Bench, and Deadlift. The dataset that we have here contains information about the competitors, the competitions, and the lifts that they performed.\n",
    "\n",
    "### What could we do with this data?\n",
    "* There is a lot of data that we can use here, but what we are more focused on is the prediction of the weight class of each person. If we can use data to predict with a very high accuracy what weight class a person should be in, it could be helpful in determining if someone is cheating or not. People could lie about their weight if there is not a weighing time. This could also show if someone is likely to be taking steroids. If they are classified as being far above the weight class than what they actually are, then investigators could look into the possiblity of them taking steroids.\n",
    "\n",
    "### What is the task we are trying to solve?\n",
    "* Given all the information that we have, specifically:\n",
    "  * Sex\n",
    "    * Sex has a large impact on how much the lifter can lift\n",
    "  * Equipment\n",
    "    * If the lifter uses straps or other apparatus, it can affect how much they can lift\n",
    "  * Age\n",
    "    * Age has a large impact on how much the lifter can lift\n",
    "  * Division\n",
    "    * A higher skill division can mean that the lifter can lift more\n",
    "  * BodyweightKg\n",
    "    * The actual weight of the lifter is a large factor in how much they can lift\n",
    "  * Best3SquatKg\n",
    "    * The best squat that the lifter did in 3 attempts\n",
    "  * Best3BenchKg\n",
    "    * The best bench that the lifter did in 3 attempts\n",
    "  * Best3DeadliftKg\n",
    "    * The best deadlift that the lifter did in 3 attempts\n",
    "  * Tested\n",
    "    * Whether or not the lifter was tested for drugs\n",
    "  * Federation\n",
    "    * The federation that held the competition\n",
    "\n",
    "We want to be able to reliably predict what Weight Class that person should be in. The target column for that data is WeightClassKg.\n",
    "\n",
    "The rest of the columns are not as important to us, so we will be dropping them.\n",
    "\n",
    "The columns to be dropped are:\n",
    "* Name\n",
    "  * The name of the lifter is irrelevant to the weight class that they should be in\n",
    "* Event\n",
    "  * The federation that held the event is irrelevant to the weight class that they should be in\n",
    "* TotalKg\n",
    "  * The total weight lifted by the lifter. This is redundant since it is just the sum of the best squat, best bench, and best deadlift, which we already have\n",
    "* AgeClass\n",
    "  * Because we already have the age of the lifter, this column is redundant\n",
    "* Squat1Kg - Squat4Kg\n",
    "  * These are the individual squat attempts, we only really care about their best one\n",
    "* Bench1Kg - Bench4Kg\n",
    "  * These are the individual bench attempts, we only really care about their best one\n",
    "* Deadlift1Kg - Deadlift4Kg\n",
    "  * These are the individual deadlift attempts, we only really care about their best one\n",
    "* Place\n",
    "  * We don't need to know where the competition was held, just the results\n",
    "* Wilks\n",
    "  * This is a calculation of the total weight lifted in relation to the weight of the lifter, which is information we are already accounting for, so it would be redundant\n",
    "* McCulloch\n",
    "  * This is another calculation method like Wilks, and for the same reason as Wilks, we will not need this.\n",
    "* Glossbrenner\n",
    "  * This is another calculation method like Wilks, and for the same reason as Wilks, we will not need this.\n",
    "* IPFPoints\n",
    "  * This is a calculation of the total weight lifted in relation to the weight of the lifter, which is information we are already accounting for, so it would be redundant\n",
    "* MeetCountry\n",
    "  * We don't need to know where the competition was held, just the results\n",
    "* MeetState\n",
    "  * We don't need to know where the competition was held, just the results\n",
    "* MeetName\n",
    "  * We don't need to know the name of the meet, just what was lifted\n",
    "* Country\n",
    "  * We don't need to know where the lifter is from, just what they lifted\n",
    "* Date\n",
    "  * We don't need to know when the competition was held, just what was lifted\n",
    "\n",
    "### What are we aiming for\n",
    "\n",
    "* If we want our classifier to be reliable, we need to have at least 90% accuracy. If we can get to that, then we can be confident that we can use this classifier to determine if someone is possibly cheating or taking steroids. That level of accuracy would be very useful for investigators. \n",
    "\n",
    "### Things to note\n",
    "* The full dataset has over 1.4 million rows of data, and that simply is more than we would like to operate on. We are going to shrink our dataset size down to 100k rows and deal with that data instead, in the interest of runtime\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_drop = [\n",
    "    'Name',\n",
    "    'Event',\n",
    "    'TotalKg',\n",
    "    'AgeClass',\n",
    "    'Squat1Kg',\n",
    "    'Squat2Kg',\n",
    "    'Squat3Kg',\n",
    "    'Squat4Kg',\n",
    "    'Bench1Kg',\n",
    "    'Bench2Kg',\n",
    "    'Bench3Kg',\n",
    "    'Bench4Kg',\n",
    "    'Deadlift1Kg',\n",
    "    'Deadlift2Kg',\n",
    "    'Deadlift3Kg',\n",
    "    'Deadlift4Kg',\n",
    "    'Place',\n",
    "    'Wilks',\n",
    "    'McCulloch',\n",
    "    'Glossbrenner',\n",
    "    'IPFPoints',\n",
    "    'MeetCountry',\n",
    "    'MeetState',\n",
    "    'MeetName',\n",
    "    'Country',\n",
    "    'Date',\n",
    "]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[.5 points] (mostly the same processes as from previous labs) Define and prepare your class variables. Use proper variable representations (int, float, one-hot, etc.). Use pre-processing methods (as needed) for dimensionality reduction, scaling, etc. Remove variables that are not needed/useful for the analysis. Describe the final dataset that is used for classification/regression (include a description of any newly formed variables you created). Provide a breakdown of the variables after preprocessing (such as the mean, std, etc. for all variables, including numeric and categorical)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initial Data Exploration\n",
    "* We will start by importing the data and looking at the first few rows to get a feel for what we are working with.\n",
    "\n",
    "* Some of the rows have NaN values, specifically in the 3 main lifts. We will give those NaN values a value of 0, since those people did not lift anything. Some of the meets did not have competitors do all 3 lifts, and we want to keep those rows, so we will just give them a value of 0 for that specific lift\n",
    "\n",
    "* We will also drop the rows that have NaN values in the WeightClassKg column, since we want to predict that column.\n",
    "\n",
    "* We took a look at how many weight classes there were, and there ended up being 13. A couple of the weight classes were in a different format, where it was 140+ or 110+ instead of the typical weight class, and we will leave those unaffected since some federations use that format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100000, 11)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sex</th>\n",
       "      <th>Equipment</th>\n",
       "      <th>Age</th>\n",
       "      <th>Division</th>\n",
       "      <th>BodyweightKg</th>\n",
       "      <th>WeightClassKg</th>\n",
       "      <th>Best3SquatKg</th>\n",
       "      <th>Best3BenchKg</th>\n",
       "      <th>Best3DeadliftKg</th>\n",
       "      <th>Tested</th>\n",
       "      <th>Federation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>F</td>\n",
       "      <td>Wraps</td>\n",
       "      <td>29.0</td>\n",
       "      <td>F-OR</td>\n",
       "      <td>59.8</td>\n",
       "      <td>60</td>\n",
       "      <td>105.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>GPC-AUS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>F</td>\n",
       "      <td>Wraps</td>\n",
       "      <td>29.0</td>\n",
       "      <td>F-OR</td>\n",
       "      <td>58.5</td>\n",
       "      <td>60</td>\n",
       "      <td>120.0</td>\n",
       "      <td>67.5</td>\n",
       "      <td>145.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>GPC-AUS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>F</td>\n",
       "      <td>Raw</td>\n",
       "      <td>40.0</td>\n",
       "      <td>F-OR</td>\n",
       "      <td>55.4</td>\n",
       "      <td>56</td>\n",
       "      <td>NaN</td>\n",
       "      <td>32.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>GPC-AUS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>F</td>\n",
       "      <td>Wraps</td>\n",
       "      <td>23.0</td>\n",
       "      <td>F-OR</td>\n",
       "      <td>60.0</td>\n",
       "      <td>60</td>\n",
       "      <td>105.0</td>\n",
       "      <td>72.5</td>\n",
       "      <td>132.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>GPC-AUS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>F</td>\n",
       "      <td>Wraps</td>\n",
       "      <td>45.0</td>\n",
       "      <td>F-OR</td>\n",
       "      <td>104.0</td>\n",
       "      <td>110</td>\n",
       "      <td>140.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>170.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>GPC-AUS</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Sex Equipment   Age Division  BodyweightKg WeightClassKg  Best3SquatKg  \\\n",
       "0   F     Wraps  29.0     F-OR          59.8            60         105.0   \n",
       "1   F     Wraps  29.0     F-OR          58.5            60         120.0   \n",
       "2   F       Raw  40.0     F-OR          55.4            56           NaN   \n",
       "3   F     Wraps  23.0     F-OR          60.0            60         105.0   \n",
       "4   F     Wraps  45.0     F-OR         104.0           110         140.0   \n",
       "\n",
       "   Best3BenchKg  Best3DeadliftKg Tested Federation  \n",
       "0          55.0            130.0    NaN    GPC-AUS  \n",
       "1          67.5            145.0    NaN    GPC-AUS  \n",
       "2          32.5              NaN    NaN    GPC-AUS  \n",
       "3          72.5            132.5    NaN    GPC-AUS  \n",
       "4          80.0            170.0    NaN    GPC-AUS  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lets look at the data\n",
    "df = pd.read_csv('./data/openpowerlifting.csv', nrows=100000)\n",
    "# Drop the columns we don't need\n",
    "df = df.drop(cols_to_drop, axis=1)\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Look at the types of Weight Classes\n",
    "* There are a ton of weight classes, and we want to reduce the number of classes that we have. We will do this by combining weight classes into categories of 30s, so all values will become their nearest factor of 30.\n",
    "* This is because these are really the only super relevant weight classes, and it will also make it easier to predict the weight class.\n",
    "* Therefore we ended with a total of 5 possible weight classes, and we will use those as our target column.\n",
    "* We decided to remove any rows that have a + at the end, since if the specification is something like 110+, then it is not a specific weight class, and we want to be able to predict a specific weight class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['60' '56' '110' '75' '82.5' '52' '67.5' '90' '110+' '125' '100' '140'\n",
      " '140+' '48' '90+' '44' nan '105' '74' '93' '120+' '120' '63' '83' '84'\n",
      " '57' '72' '84+' '47' '59' '66' '53' '125+' '43' '100+' '90.7' '90.7+'\n",
      " '36' '40' '46' '49' '75+' '82.5+' '52+' '145' '145+' '72+' '93+' '60+'\n",
      " '50' '65' '80' '80+' '67.5+' '105+' '63+' '35' '155' '39' '155+' '68'\n",
      " '50.5' '55.5' '58.5' '70' '47.5' '136' '136+' '55' '54.4' '58.9' '63.5'\n",
      " '68.9' '78.9' '78.9+' '56.7' '83.9' '102' '113.4' '127' '127+' '117.5'\n",
      " '101' '103' '67' '82' '36.2' '52.5' '72.5' '81.6' '104.3' '117.9'\n",
      " '117.9+' '79.3' '113.4+' '49.9' '57.1' '70.3' '77.1' '92.9' '68.5' '69.5'\n",
      " '70.5' '71.5' '73.5' '74.5' '75.5' '76.5' '77.5' '78.5' '79.5' '80.5'\n",
      " '81.5']\n",
      "Original Number of Classes:  113\n",
      "['60' '120' '90' '150' '30']\n",
      "Total Number of Classes:  5\n"
     ]
    }
   ],
   "source": [
    "# Lets look at some unique values that might be worth encoding, specifically our weight classes\n",
    "print(df['WeightClassKg'].unique())\n",
    "print(\"Original Number of Classes: \", len(df['WeightClassKg'].unique()))\n",
    "\n",
    "# Remove all rows with a NaN value for weight class, since that is the value we are trying to predict\n",
    "df = df.dropna(subset=['WeightClassKg'])\n",
    "\n",
    "# All the rows with a + at the end do not give us enough information to predict the weight class.\n",
    "# We will remove them\n",
    "df = df[~df['WeightClassKg'].str.contains('\\+')]\n",
    "\n",
    "# Convert to float\n",
    "df['WeightClassKg'] = df['WeightClassKg'].astype(float)\n",
    "\n",
    "# Convert all values between factors of ten rounded up to the nearest factor of 30\n",
    "df['WeightClassKg'] = df['WeightClassKg'].apply(lambda x: 30 * round(x / 30))\n",
    "\n",
    "# Make it a string again so that it can be treated as a categorical variable\n",
    "df['WeightClassKg'] = df['WeightClassKg'].astype(str)\n",
    "\n",
    "# look at it real quick\n",
    "print(df['WeightClassKg'].unique())\n",
    "print(\"Total Number of Classes: \", len(df['WeightClassKg'].unique()))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tested Column\n",
    "* This gives us information about whether the lifter was tested for drugs or not. We will convert this to a boolean column, where 1 means that they were tested, and 0 means that they were not tested. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sex</th>\n",
       "      <th>Equipment</th>\n",
       "      <th>Age</th>\n",
       "      <th>Division</th>\n",
       "      <th>BodyweightKg</th>\n",
       "      <th>WeightClassKg</th>\n",
       "      <th>Best3SquatKg</th>\n",
       "      <th>Best3BenchKg</th>\n",
       "      <th>Best3DeadliftKg</th>\n",
       "      <th>Tested</th>\n",
       "      <th>Federation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>F</td>\n",
       "      <td>Wraps</td>\n",
       "      <td>29.0</td>\n",
       "      <td>F-OR</td>\n",
       "      <td>59.8</td>\n",
       "      <td>60</td>\n",
       "      <td>105.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>0</td>\n",
       "      <td>GPC-AUS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>F</td>\n",
       "      <td>Wraps</td>\n",
       "      <td>29.0</td>\n",
       "      <td>F-OR</td>\n",
       "      <td>58.5</td>\n",
       "      <td>60</td>\n",
       "      <td>120.0</td>\n",
       "      <td>67.5</td>\n",
       "      <td>145.0</td>\n",
       "      <td>0</td>\n",
       "      <td>GPC-AUS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>F</td>\n",
       "      <td>Raw</td>\n",
       "      <td>40.0</td>\n",
       "      <td>F-OR</td>\n",
       "      <td>55.4</td>\n",
       "      <td>60</td>\n",
       "      <td>NaN</td>\n",
       "      <td>32.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>GPC-AUS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>F</td>\n",
       "      <td>Wraps</td>\n",
       "      <td>23.0</td>\n",
       "      <td>F-OR</td>\n",
       "      <td>60.0</td>\n",
       "      <td>60</td>\n",
       "      <td>105.0</td>\n",
       "      <td>72.5</td>\n",
       "      <td>132.5</td>\n",
       "      <td>0</td>\n",
       "      <td>GPC-AUS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>F</td>\n",
       "      <td>Wraps</td>\n",
       "      <td>45.0</td>\n",
       "      <td>F-OR</td>\n",
       "      <td>104.0</td>\n",
       "      <td>120</td>\n",
       "      <td>140.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>170.0</td>\n",
       "      <td>0</td>\n",
       "      <td>GPC-AUS</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Sex Equipment   Age Division  BodyweightKg WeightClassKg  Best3SquatKg  \\\n",
       "0   F     Wraps  29.0     F-OR          59.8            60         105.0   \n",
       "1   F     Wraps  29.0     F-OR          58.5            60         120.0   \n",
       "2   F       Raw  40.0     F-OR          55.4            60           NaN   \n",
       "3   F     Wraps  23.0     F-OR          60.0            60         105.0   \n",
       "4   F     Wraps  45.0     F-OR         104.0           120         140.0   \n",
       "\n",
       "   Best3BenchKg  Best3DeadliftKg  Tested Federation  \n",
       "0          55.0            130.0       0    GPC-AUS  \n",
       "1          67.5            145.0       0    GPC-AUS  \n",
       "2          32.5              NaN       0    GPC-AUS  \n",
       "3          72.5            132.5       0    GPC-AUS  \n",
       "4          80.0            170.0       0    GPC-AUS  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(df['Tested'].unique())\n",
    "# Convert NaN to 0, and 'Yes' to 1\n",
    "df['Tested'] = df['Tested'].fillna(0)\n",
    "df['Tested'] = df['Tested'].replace('Yes', 1)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Look at the types of Divisions\n",
    "  * We can turn these into one hot encoded columns, since they are representative of different categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['F-OR' 'M-OR' 'M-OE' 'F-OE' 'F-GR' 'F-JR' 'F-T3R' 'F-T2R' 'F-M5R' 'F-M1R'\n",
      " 'F-M2R' 'F-T1R' 'F-M3R' 'M-JR' 'M-M3R' 'M-M1R' 'M-M2R' 'M-T2R' 'M-T1R'\n",
      " 'M-M6R' 'M-T3R' 'M-M4R' 'M-M5R' 'M-TR' 'M-JE' 'F-TR' 'F-M4R' 'F-M7R'\n",
      " 'M-M8R' 'Youth A' 'Juniors' 'Open' 'Masters 1' 'Masters 4' 'Masters 2'\n",
      " 'Youth B' 'Masters 3' 'Sub-Juniors' 'Youth' 'Teen' 'M1' 'M5' 'M4' 'M2'\n",
      " 'M3' nan 'Teen 18-19' 'Juniors 20-23' 'Teen 16-17' 'Masters 40-44'\n",
      " 'Masters 50-54' 'Teen 3' 'Teen 2' 'Masters' 'Teen 1' 'Masters 60-64'\n",
      " 'Submasters 35-39' 'Masters 55-59' 'Police/Fire' 'Teen 13-15'\n",
      " 'Submasters 33-39' 'Masters 45-49' 'Masters 65-69' 'Masters 70-74'\n",
      " 'Juniors 19-20' 'Military' 'Teen 15-16' 'Juniors 21-23' 'Masters 75-79'\n",
      " 'Teen 14-15' 'Masters 80+' 'Masters 40+' 'M-O' 'F-O' 'F-J' 'F-T2' 'F-T1'\n",
      " 'F-M1' 'M-T1' 'F-M2' 'M-T2' 'M-J' 'M-M1' 'M-T3' 'M-M5' 'M-M2' 'M-EM6'\n",
      " 'M-M4' 'M-M3' 'M-SM' 'M-M6' 'F-SM' 'M-EM2' 'M-EM1' 'M-H' 'M-M' 'M-B'\n",
      " 'F-H' 'F-L' 'M-L' 'F-MW' 'F-LW' 'M-LW' 'M-MW' 'M-HW' 'F-HW' 'M-Hw' 'F-B'\n",
      " 'M-HWB' 'M-MWB' 'M-LWB' 'O' 'LW' 'HW' 'Tn 16-17' 'Junior' 'M 45-49'\n",
      " 'M 50-54' 'Tn 13-15' 'Tn 18-19' 'M 50-59' 'M 40-49' 'Student'\n",
      " 'Teen 12-14' 'Teen 17-18' 'Disabled' 'Youth 11-13' 'Teen 16-18'\n",
      " 'Youth 10-15' 'J' 'T2' 'T1' 'M6' 'T3' 'PFM' 'M7' 'Am O' 'Am J' 'Pro O'\n",
      " 'Am M' 'M40+' 'M45+' 'M50+' 'M55+' 'M60+' 'M65+' 'Jun' 'Teen U19'\n",
      " 'Junior U23' 'Junior U19' 'M70+' 'Teen 15-19' 'T' 'M60-64' 'M50-54'\n",
      " 'M40-44' 'M45-49' 'M55-59' 'WM 40+' 'WM 45+' 'M 40+' 'M 45+' 'M 50+'\n",
      " 'M 60+' 'M 65+' 'M 55+' 'M 70+' 'M8' '55+' '45+' '60+' 'Under 19' '65+'\n",
      " 'Under 23' '75+' '50+' '40+' '70+' 'M65-69' 'M70-74' 'M-PP' 'M-OC' 'F-OC'\n",
      " 'F-OM' 'F-BO' 'M-OS' 'M-OM' 'High School' 'Teachers' 'Firefighter'\n",
      " 'Police' 'Self Defense Force' 'Blind' 'Masters 5' 'Guest' 'SJ' 'Novice'\n",
      " 'Youth 12-13' 'Law & Military' 'Kids 10-11' 'F-C-M1' 'F-C-Open' 'F-C-U23'\n",
      " 'M-C-M2' 'M-C-M1' 'M-C-Open' 'M-C-U23' 'M-C-U18' 'F-C-M2' 'M-E-U18'\n",
      " 'M-E-G' 'M-E-Open' 'M-E-M4' 'M-E-M1' 'F-E-Open' 'F-C-U18' 'M-E-U23'\n",
      " 'Submasters' 'Masters 50-59' 'Masters 60-69' 'Masters 40-49'\n",
      " 'Masters 70-79' 'Masters 50+' 'Masters 60+' 'Youth 10-11' 'Youth 8-9'\n",
      " 'Veterans' 'Special Olympics' 'Paralympics' 'Youth 11-12' 'Youth 8-10'\n",
      " 'Youth 9-10' 'Handicapped' 'MW' 'Masters 75+' 'Masters 65'\n",
      " 'Open Drug Tested' 'Pro Cash Division' 'LWT' 'HWT' 'М3' 'М1' 'М2'\n",
      " 'Юниорки' 'Юноши' 'Девушки' 'M 40-44' 'M 75-79' 'Teenage' 'M 65-69'\n",
      " 'M 55-59' 'Juniors 16-17' 'OR' 'M3R' 'J4R' 'OC' 'M1C' 'M2C' 'OSP' 'OMP'\n",
      " 'M1SP' 'J1R' 'M2SP' 'J4C' 'J2R' 'Below Class I' 'F-E-M1' 'F-E-M2'\n",
      " 'M-E-M2' 'M-E-M3' 'Special Olympics Teen' 'Special Olympics Masters'\n",
      " 'Amateur Open' 'Amateur Submasters' 'Amateur Masters' 'Pro Open'\n",
      " 'Pro Juniors' 'Pro Masters 60-64' 'Amateur Teen 16-17'\n",
      " 'Amateur Teen 18-19' 'Amateur Juniors' 'Amateur Masters 50-54'\n",
      " 'Amateur Masters 40-44' 'Amateur Masters 55-59' 'Amateur Masters 45-49'\n",
      " 'Elite Amateur Open' 'Pro Submasters' 'pro Masters 55-59'\n",
      " 'Pro Masters 50-54' 'Pro Masters 55-59' 'Pro Masters 45-49'\n",
      " 'Pro Masters 40-44' 'Law' 'Natural' 'Lifetime'\n",
      " 'Submasters Physically Challenged' 'Physically Challenged' 'Teen 17-19'\n",
      " 'Teen 14-16' 'Police/Fire/Military' 'M' 'Masters 35-44' 'Youth 5-16' 'SM'\n",
      " 'LT' '17-19' '20-23' '13-16' '60-69' '40-49' '50-59' 'JR' 'SO' 'NV'\n",
      " 'Under 20' 'Class II' 'Masters 70+' 'Collegiate' 'F-E-M3' 'F-E-G'\n",
      " 'Masters 40-59' 'Open Masters 1' 'M-C-U20' 'M-C-M3' 'M-C-M4' 'F-C-U20'\n",
      " 'F-C-M3' 'Masters 6' '0/60' 'Below Class II' 'Below Class III'\n",
      " 'Law/Fire Open' 'Law/Fire Masters 40-46' 'Masters 54-60' 'Class I'\n",
      " 'Elite Open' 'Juniors 20-25' 'Law/Fire Submasters 33-39' 'Masters 40-46'\n",
      " 'Masters 47-53' 'Masters 68-74' 'Teen 12-13' 'Teen 16-19' 'Masters 61-67'\n",
      " 'Class III' 'P/F/M' 'Police & Fire' 'Juniors 20-24' 'Juniors 20-26'\n",
      " 'Juniors 20-27' 'F-E-U18' 'F-E-U20' 'M-E-U20' 'law' 'Masters 65-79'\n",
      " 'Freshman-Sophmore' 'Juniors-Senior' 'Class II & Below' 'Senior' 'Pure'\n",
      " '14-16' 'Teen 17' 'Teen 15' 'Teen 18' 'Teen 19' 'Amateur' 'VIC' 'I/V'\n",
      " 'Special Olympics Open' 'Pro Masters' 'Special Olympics Teen 16-19'\n",
      " 'Special Olympics Masters 30+' 'Amateur Teen' 'Amateur Masters 65-69'\n",
      " 'Amateur Masters 70-74' 'Amateur Police' 'Pro Masters 70-74'\n",
      " 'Pro Masters 75-79' 'Grandmasters' 'Masters 80-84' 'M-C-G' 'Pure Novice'\n",
      " 'Submasters 1' 'Submasters 2' '9-10' 'M9' 'Special Olympics (Juniors)'\n",
      " 'Class 2' 'Submasters 36-39' 'Submasters 33-35' 'Amateur Masters 60-64'\n",
      " 'Amateur Teen 14-15' 'Out of State' 'Teen 13-14' 'M-E-Guest'\n",
      " 'Masters 40-49 Light' 'Masters 50-59 Light' 'Law Masters 40-44'\n",
      " 'Law Masters 45-49' 'Law Submasters' 'Submasters 35-40'\n",
      " 'Submasters 35-41' 'Submasters 35-42' 'Submasters 35-43'\n",
      " 'Submasters 35-44' 'Pro' 'Law/Fire' 'Masters Law/Fire 38-47'\n",
      " 'Masters Law/Fire 48+' 'Class 1' 'Masters 45-54' '40-44' '45-49' '50-54'\n",
      " '55-59' '65-69' 'High School Pure' 'Law/Fire Masters 40-47'\n",
      " 'Law/Fire Masters 48+' 'Law/Fire Submasters' 'Submasters 34-39' 'F-E-U23'\n",
      " 'Region IX' 'Youth 10-12' 'Teen 13-16' 'LW Masters' 'HW Masters']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sex</th>\n",
       "      <th>Equipment</th>\n",
       "      <th>Age</th>\n",
       "      <th>BodyweightKg</th>\n",
       "      <th>WeightClassKg</th>\n",
       "      <th>Best3SquatKg</th>\n",
       "      <th>Best3BenchKg</th>\n",
       "      <th>Best3DeadliftKg</th>\n",
       "      <th>Tested</th>\n",
       "      <th>Federation</th>\n",
       "      <th>...</th>\n",
       "      <th>Division_Youth A</th>\n",
       "      <th>Division_Youth B</th>\n",
       "      <th>Division_law</th>\n",
       "      <th>Division_pro Masters 55-59</th>\n",
       "      <th>Division_Девушки</th>\n",
       "      <th>Division_М1</th>\n",
       "      <th>Division_М2</th>\n",
       "      <th>Division_М3</th>\n",
       "      <th>Division_Юниорки</th>\n",
       "      <th>Division_Юноши</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>F</td>\n",
       "      <td>Wraps</td>\n",
       "      <td>29.0</td>\n",
       "      <td>59.8</td>\n",
       "      <td>60</td>\n",
       "      <td>105.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>0</td>\n",
       "      <td>GPC-AUS</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>F</td>\n",
       "      <td>Wraps</td>\n",
       "      <td>29.0</td>\n",
       "      <td>58.5</td>\n",
       "      <td>60</td>\n",
       "      <td>120.0</td>\n",
       "      <td>67.5</td>\n",
       "      <td>145.0</td>\n",
       "      <td>0</td>\n",
       "      <td>GPC-AUS</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>F</td>\n",
       "      <td>Raw</td>\n",
       "      <td>40.0</td>\n",
       "      <td>55.4</td>\n",
       "      <td>60</td>\n",
       "      <td>NaN</td>\n",
       "      <td>32.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>GPC-AUS</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>F</td>\n",
       "      <td>Wraps</td>\n",
       "      <td>23.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>60</td>\n",
       "      <td>105.0</td>\n",
       "      <td>72.5</td>\n",
       "      <td>132.5</td>\n",
       "      <td>0</td>\n",
       "      <td>GPC-AUS</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>F</td>\n",
       "      <td>Wraps</td>\n",
       "      <td>45.0</td>\n",
       "      <td>104.0</td>\n",
       "      <td>120</td>\n",
       "      <td>140.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>170.0</td>\n",
       "      <td>0</td>\n",
       "      <td>GPC-AUS</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 436 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  Sex Equipment   Age  BodyweightKg WeightClassKg  Best3SquatKg  Best3BenchKg  \\\n",
       "0   F     Wraps  29.0          59.8            60         105.0          55.0   \n",
       "1   F     Wraps  29.0          58.5            60         120.0          67.5   \n",
       "2   F       Raw  40.0          55.4            60           NaN          32.5   \n",
       "3   F     Wraps  23.0          60.0            60         105.0          72.5   \n",
       "4   F     Wraps  45.0         104.0           120         140.0          80.0   \n",
       "\n",
       "   Best3DeadliftKg  Tested Federation  ...  Division_Youth A  \\\n",
       "0            130.0       0    GPC-AUS  ...                 0   \n",
       "1            145.0       0    GPC-AUS  ...                 0   \n",
       "2              NaN       0    GPC-AUS  ...                 0   \n",
       "3            132.5       0    GPC-AUS  ...                 0   \n",
       "4            170.0       0    GPC-AUS  ...                 0   \n",
       "\n",
       "   Division_Youth B  Division_law  Division_pro Masters 55-59  \\\n",
       "0                 0             0                           0   \n",
       "1                 0             0                           0   \n",
       "2                 0             0                           0   \n",
       "3                 0             0                           0   \n",
       "4                 0             0                           0   \n",
       "\n",
       "   Division_Девушки  Division_М1  Division_М2  Division_М3  Division_Юниорки  \\\n",
       "0                 0            0            0            0                 0   \n",
       "1                 0            0            0            0                 0   \n",
       "2                 0            0            0            0                 0   \n",
       "3                 0            0            0            0                 0   \n",
       "4                 0            0            0            0                 0   \n",
       "\n",
       "   Division_Юноши  \n",
       "0               0  \n",
       "1               0  \n",
       "2               0  \n",
       "3               0  \n",
       "4               0  \n",
       "\n",
       "[5 rows x 436 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(df['Division'].unique())\n",
    "\n",
    "# One hot encode that column\n",
    "df = pd.get_dummies(df, columns=['Division'])\n",
    "df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Federation\n",
    "* Federations clearly are a categorical datatype, so we will one hot encode them as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['GPC-AUS' 'BVDK' 'GPU' 'GPA-CRO' 'USPF' 'RhinoPC' 'RUPC' 'ACHIPO'\n",
      " 'USSports' 'UkrainePF' 'UkrainePA' 'WPF' 'USA-UA' 'ADFPA' 'JPA'\n",
      " 'WPC-Germany' 'PLZS' 'NORCAL' 'WelshPA' 'SSA' 'APA' 'WPA' 'WRPF-KAZ'\n",
      " 'WUAP-AUT' 'WRPF-POL' 'IPL-NZ' 'APF' 'USMilAbroad' 'AAU' 'BAWLA' 'IPF'\n",
      " 'PA' 'NZPF' 'AusPF' 'WDFPF' 'IPA' 'WNPF' 'SCI' 'WPC' 'AAPLF' 'SLP'\n",
      " 'IrishPF' 'CAPO' 'UPA' 'IBSA' 'WABDL' 'ScottishPL' 'EPF' 'AIWBPA' 'BDFPA'\n",
      " 'NASA' 'BPO' 'USAPL' 'OceaniaPF' 'FPR' 'USARawBP' 'AusDFPF' 'THSPA'\n",
      " 'BBDD' 'BPF' 'WBC']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sex</th>\n",
       "      <th>Equipment</th>\n",
       "      <th>Age</th>\n",
       "      <th>BodyweightKg</th>\n",
       "      <th>WeightClassKg</th>\n",
       "      <th>Best3SquatKg</th>\n",
       "      <th>Best3BenchKg</th>\n",
       "      <th>Best3DeadliftKg</th>\n",
       "      <th>Tested</th>\n",
       "      <th>Division_0/60</th>\n",
       "      <th>...</th>\n",
       "      <th>Federation_WDFPF</th>\n",
       "      <th>Federation_WNPF</th>\n",
       "      <th>Federation_WPA</th>\n",
       "      <th>Federation_WPC</th>\n",
       "      <th>Federation_WPC-Germany</th>\n",
       "      <th>Federation_WPF</th>\n",
       "      <th>Federation_WRPF-KAZ</th>\n",
       "      <th>Federation_WRPF-POL</th>\n",
       "      <th>Federation_WUAP-AUT</th>\n",
       "      <th>Federation_WelshPA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>F</td>\n",
       "      <td>Wraps</td>\n",
       "      <td>29.0</td>\n",
       "      <td>59.8</td>\n",
       "      <td>60</td>\n",
       "      <td>105.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>F</td>\n",
       "      <td>Wraps</td>\n",
       "      <td>29.0</td>\n",
       "      <td>58.5</td>\n",
       "      <td>60</td>\n",
       "      <td>120.0</td>\n",
       "      <td>67.5</td>\n",
       "      <td>145.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>F</td>\n",
       "      <td>Raw</td>\n",
       "      <td>40.0</td>\n",
       "      <td>55.4</td>\n",
       "      <td>60</td>\n",
       "      <td>NaN</td>\n",
       "      <td>32.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>F</td>\n",
       "      <td>Wraps</td>\n",
       "      <td>23.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>60</td>\n",
       "      <td>105.0</td>\n",
       "      <td>72.5</td>\n",
       "      <td>132.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>F</td>\n",
       "      <td>Wraps</td>\n",
       "      <td>45.0</td>\n",
       "      <td>104.0</td>\n",
       "      <td>120</td>\n",
       "      <td>140.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>170.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 496 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  Sex Equipment   Age  BodyweightKg WeightClassKg  Best3SquatKg  Best3BenchKg  \\\n",
       "0   F     Wraps  29.0          59.8            60         105.0          55.0   \n",
       "1   F     Wraps  29.0          58.5            60         120.0          67.5   \n",
       "2   F       Raw  40.0          55.4            60           NaN          32.5   \n",
       "3   F     Wraps  23.0          60.0            60         105.0          72.5   \n",
       "4   F     Wraps  45.0         104.0           120         140.0          80.0   \n",
       "\n",
       "   Best3DeadliftKg  Tested  Division_0/60  ...  Federation_WDFPF  \\\n",
       "0            130.0       0              0  ...                 0   \n",
       "1            145.0       0              0  ...                 0   \n",
       "2              NaN       0              0  ...                 0   \n",
       "3            132.5       0              0  ...                 0   \n",
       "4            170.0       0              0  ...                 0   \n",
       "\n",
       "   Federation_WNPF  Federation_WPA  Federation_WPC  Federation_WPC-Germany  \\\n",
       "0                0               0               0                       0   \n",
       "1                0               0               0                       0   \n",
       "2                0               0               0                       0   \n",
       "3                0               0               0                       0   \n",
       "4                0               0               0                       0   \n",
       "\n",
       "   Federation_WPF  Federation_WRPF-KAZ  Federation_WRPF-POL  \\\n",
       "0               0                    0                    0   \n",
       "1               0                    0                    0   \n",
       "2               0                    0                    0   \n",
       "3               0                    0                    0   \n",
       "4               0                    0                    0   \n",
       "\n",
       "   Federation_WUAP-AUT  Federation_WelshPA  \n",
       "0                    0                   0  \n",
       "1                    0                   0  \n",
       "2                    0                   0  \n",
       "3                    0                   0  \n",
       "4                    0                   0  \n",
       "\n",
       "[5 rows x 496 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(df['Federation'].unique())\n",
    "\n",
    "# One Hot Encode the Federation column\n",
    "df = pd.get_dummies(df, columns=['Federation'])\n",
    "df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Look at the Equipment\n",
    "* Since there are only a few options, we can one-hot encode that column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Wraps' 'Raw' 'Single-ply' 'Multi-ply' 'Straps']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>BodyweightKg</th>\n",
       "      <th>WeightClassKg</th>\n",
       "      <th>Best3SquatKg</th>\n",
       "      <th>Best3BenchKg</th>\n",
       "      <th>Best3DeadliftKg</th>\n",
       "      <th>Tested</th>\n",
       "      <th>Division_0/60</th>\n",
       "      <th>Division_13-16</th>\n",
       "      <th>...</th>\n",
       "      <th>Federation_WPF</th>\n",
       "      <th>Federation_WRPF-KAZ</th>\n",
       "      <th>Federation_WRPF-POL</th>\n",
       "      <th>Federation_WUAP-AUT</th>\n",
       "      <th>Federation_WelshPA</th>\n",
       "      <th>Equipment_Multi-ply</th>\n",
       "      <th>Equipment_Raw</th>\n",
       "      <th>Equipment_Single-ply</th>\n",
       "      <th>Equipment_Straps</th>\n",
       "      <th>Equipment_Wraps</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>F</td>\n",
       "      <td>29.0</td>\n",
       "      <td>59.8</td>\n",
       "      <td>60</td>\n",
       "      <td>105.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>F</td>\n",
       "      <td>29.0</td>\n",
       "      <td>58.5</td>\n",
       "      <td>60</td>\n",
       "      <td>120.0</td>\n",
       "      <td>67.5</td>\n",
       "      <td>145.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>F</td>\n",
       "      <td>40.0</td>\n",
       "      <td>55.4</td>\n",
       "      <td>60</td>\n",
       "      <td>NaN</td>\n",
       "      <td>32.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>F</td>\n",
       "      <td>23.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>60</td>\n",
       "      <td>105.0</td>\n",
       "      <td>72.5</td>\n",
       "      <td>132.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>F</td>\n",
       "      <td>45.0</td>\n",
       "      <td>104.0</td>\n",
       "      <td>120</td>\n",
       "      <td>140.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>170.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 500 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  Sex   Age  BodyweightKg WeightClassKg  Best3SquatKg  Best3BenchKg  \\\n",
       "0   F  29.0          59.8            60         105.0          55.0   \n",
       "1   F  29.0          58.5            60         120.0          67.5   \n",
       "2   F  40.0          55.4            60           NaN          32.5   \n",
       "3   F  23.0          60.0            60         105.0          72.5   \n",
       "4   F  45.0         104.0           120         140.0          80.0   \n",
       "\n",
       "   Best3DeadliftKg  Tested  Division_0/60  Division_13-16  ...  \\\n",
       "0            130.0       0              0               0  ...   \n",
       "1            145.0       0              0               0  ...   \n",
       "2              NaN       0              0               0  ...   \n",
       "3            132.5       0              0               0  ...   \n",
       "4            170.0       0              0               0  ...   \n",
       "\n",
       "   Federation_WPF  Federation_WRPF-KAZ  Federation_WRPF-POL  \\\n",
       "0               0                    0                    0   \n",
       "1               0                    0                    0   \n",
       "2               0                    0                    0   \n",
       "3               0                    0                    0   \n",
       "4               0                    0                    0   \n",
       "\n",
       "   Federation_WUAP-AUT  Federation_WelshPA  Equipment_Multi-ply  \\\n",
       "0                    0                   0                    0   \n",
       "1                    0                   0                    0   \n",
       "2                    0                   0                    0   \n",
       "3                    0                   0                    0   \n",
       "4                    0                   0                    0   \n",
       "\n",
       "   Equipment_Raw  Equipment_Single-ply  Equipment_Straps  Equipment_Wraps  \n",
       "0              0                     0                 0                1  \n",
       "1              0                     0                 0                1  \n",
       "2              1                     0                 0                0  \n",
       "3              0                     0                 0                1  \n",
       "4              0                     0                 0                1  \n",
       "\n",
       "[5 rows x 500 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(df['Equipment'].unique())\n",
    "\n",
    "# One hot encode that column\n",
    "df = pd.get_dummies(df, columns=['Equipment'])\n",
    "df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sex\n",
    "* Since there are only two options here, we will one-hot encode this column as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['F' 'M']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>BodyweightKg</th>\n",
       "      <th>WeightClassKg</th>\n",
       "      <th>Best3SquatKg</th>\n",
       "      <th>Best3BenchKg</th>\n",
       "      <th>Best3DeadliftKg</th>\n",
       "      <th>Tested</th>\n",
       "      <th>Division_0/60</th>\n",
       "      <th>Division_13-16</th>\n",
       "      <th>Division_14-16</th>\n",
       "      <th>...</th>\n",
       "      <th>Federation_WRPF-POL</th>\n",
       "      <th>Federation_WUAP-AUT</th>\n",
       "      <th>Federation_WelshPA</th>\n",
       "      <th>Equipment_Multi-ply</th>\n",
       "      <th>Equipment_Raw</th>\n",
       "      <th>Equipment_Single-ply</th>\n",
       "      <th>Equipment_Straps</th>\n",
       "      <th>Equipment_Wraps</th>\n",
       "      <th>Sex_F</th>\n",
       "      <th>Sex_M</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>29.0</td>\n",
       "      <td>59.8</td>\n",
       "      <td>60</td>\n",
       "      <td>105.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>29.0</td>\n",
       "      <td>58.5</td>\n",
       "      <td>60</td>\n",
       "      <td>120.0</td>\n",
       "      <td>67.5</td>\n",
       "      <td>145.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>40.0</td>\n",
       "      <td>55.4</td>\n",
       "      <td>60</td>\n",
       "      <td>NaN</td>\n",
       "      <td>32.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>23.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>60</td>\n",
       "      <td>105.0</td>\n",
       "      <td>72.5</td>\n",
       "      <td>132.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>45.0</td>\n",
       "      <td>104.0</td>\n",
       "      <td>120</td>\n",
       "      <td>140.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>170.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 501 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Age  BodyweightKg WeightClassKg  Best3SquatKg  Best3BenchKg  \\\n",
       "0  29.0          59.8            60         105.0          55.0   \n",
       "1  29.0          58.5            60         120.0          67.5   \n",
       "2  40.0          55.4            60           NaN          32.5   \n",
       "3  23.0          60.0            60         105.0          72.5   \n",
       "4  45.0         104.0           120         140.0          80.0   \n",
       "\n",
       "   Best3DeadliftKg  Tested  Division_0/60  Division_13-16  Division_14-16  \\\n",
       "0            130.0       0              0               0               0   \n",
       "1            145.0       0              0               0               0   \n",
       "2              NaN       0              0               0               0   \n",
       "3            132.5       0              0               0               0   \n",
       "4            170.0       0              0               0               0   \n",
       "\n",
       "   ...  Federation_WRPF-POL  Federation_WUAP-AUT  Federation_WelshPA  \\\n",
       "0  ...                    0                    0                   0   \n",
       "1  ...                    0                    0                   0   \n",
       "2  ...                    0                    0                   0   \n",
       "3  ...                    0                    0                   0   \n",
       "4  ...                    0                    0                   0   \n",
       "\n",
       "   Equipment_Multi-ply  Equipment_Raw  Equipment_Single-ply  Equipment_Straps  \\\n",
       "0                    0              0                     0                 0   \n",
       "1                    0              0                     0                 0   \n",
       "2                    0              1                     0                 0   \n",
       "3                    0              0                     0                 0   \n",
       "4                    0              0                     0                 0   \n",
       "\n",
       "   Equipment_Wraps  Sex_F  Sex_M  \n",
       "0                1      1      0  \n",
       "1                1      1      0  \n",
       "2                0      1      0  \n",
       "3                1      1      0  \n",
       "4                1      1      0  \n",
       "\n",
       "[5 rows x 501 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(df['Sex'].unique())\n",
    "\n",
    "# One hot encode that column\n",
    "df = pd.get_dummies(df, columns=['Sex'])\n",
    "df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removing NaN values in the 3 main lifts\n",
    "* Some of the competitions made it so that the competitors did not have to compete in all 3 lifts, so we will give those NaN values a value of the average for that weight class, since those people did not lift anything. It would scew the data pretty horribly if we just gave them a value of 0, since that would mean that they lifted 0kg in that lift, which is not true.\n",
    "\n",
    "* The other option, removing that row, is not really an option because then we get left with a pretty small dataset, with only a few rows (around 5 haha!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make all Nan values the average of the column for that person's weight class\n",
    "df['Best3SquatKg'] = df.groupby('WeightClassKg')['Best3SquatKg'].transform(lambda x: x.fillna(x.mean()))\n",
    "df['Best3BenchKg'] = df.groupby('WeightClassKg')['Best3BenchKg'].transform(lambda x: x.fillna(x.mean()))\n",
    "df['Best3DeadliftKg'] = df.groupby('WeightClassKg')['Best3DeadliftKg'].transform(lambda x: x.fillna(x.mean()))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removing NaN values in the Age column\n",
    "* Some of the entries did not have an Age column, and that is something we find very important to the weight class that they should be in, so we will remove those rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove NaN in Age column\n",
    "df = df.dropna(subset=['Age'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scaling the data\n",
    "* We will scale the data using the StandardScaler, since it is a good way to scale the data without distorting the shape of the data.\n",
    "\n",
    "* The types of data that we need to scale are the Age, BodyweightKg, Best3SquatKg, Best3BenchKg, and Best3DeadliftKg columns. We will scale those columns, and then we will concatenate them with the other columns that we have already one-hot encoded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>BodyweightKg</th>\n",
       "      <th>WeightClassKg</th>\n",
       "      <th>Best3SquatKg</th>\n",
       "      <th>Best3BenchKg</th>\n",
       "      <th>Best3DeadliftKg</th>\n",
       "      <th>Tested</th>\n",
       "      <th>Division_0/60</th>\n",
       "      <th>Division_13-16</th>\n",
       "      <th>Division_14-16</th>\n",
       "      <th>...</th>\n",
       "      <th>Federation_WRPF-POL</th>\n",
       "      <th>Federation_WUAP-AUT</th>\n",
       "      <th>Federation_WelshPA</th>\n",
       "      <th>Equipment_Multi-ply</th>\n",
       "      <th>Equipment_Raw</th>\n",
       "      <th>Equipment_Single-ply</th>\n",
       "      <th>Equipment_Straps</th>\n",
       "      <th>Equipment_Wraps</th>\n",
       "      <th>Sex_F</th>\n",
       "      <th>Sex_M</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.159545</td>\n",
       "      <td>-0.997664</td>\n",
       "      <td>60</td>\n",
       "      <td>-1.324652</td>\n",
       "      <td>-1.395555</td>\n",
       "      <td>-1.278240</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.159545</td>\n",
       "      <td>-1.062647</td>\n",
       "      <td>60</td>\n",
       "      <td>-1.092358</td>\n",
       "      <td>-1.151556</td>\n",
       "      <td>-1.013500</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.635782</td>\n",
       "      <td>-1.217606</td>\n",
       "      <td>60</td>\n",
       "      <td>-0.617433</td>\n",
       "      <td>-1.834752</td>\n",
       "      <td>-0.626826</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.593359</td>\n",
       "      <td>-0.987667</td>\n",
       "      <td>60</td>\n",
       "      <td>-1.324652</td>\n",
       "      <td>-1.053956</td>\n",
       "      <td>-1.234117</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.997294</td>\n",
       "      <td>1.211747</td>\n",
       "      <td>120</td>\n",
       "      <td>-0.782633</td>\n",
       "      <td>-0.907557</td>\n",
       "      <td>-0.572267</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 501 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Age  BodyweightKg WeightClassKg  Best3SquatKg  Best3BenchKg  \\\n",
       "0 -0.159545     -0.997664            60     -1.324652     -1.395555   \n",
       "1 -0.159545     -1.062647            60     -1.092358     -1.151556   \n",
       "2  0.635782     -1.217606            60     -0.617433     -1.834752   \n",
       "3 -0.593359     -0.987667            60     -1.324652     -1.053956   \n",
       "4  0.997294      1.211747           120     -0.782633     -0.907557   \n",
       "\n",
       "   Best3DeadliftKg  Tested  Division_0/60  Division_13-16  Division_14-16  \\\n",
       "0        -1.278240       0              0               0               0   \n",
       "1        -1.013500       0              0               0               0   \n",
       "2        -0.626826       0              0               0               0   \n",
       "3        -1.234117       0              0               0               0   \n",
       "4        -0.572267       0              0               0               0   \n",
       "\n",
       "   ...  Federation_WRPF-POL  Federation_WUAP-AUT  Federation_WelshPA  \\\n",
       "0  ...                    0                    0                   0   \n",
       "1  ...                    0                    0                   0   \n",
       "2  ...                    0                    0                   0   \n",
       "3  ...                    0                    0                   0   \n",
       "4  ...                    0                    0                   0   \n",
       "\n",
       "   Equipment_Multi-ply  Equipment_Raw  Equipment_Single-ply  Equipment_Straps  \\\n",
       "0                    0              0                     0                 0   \n",
       "1                    0              0                     0                 0   \n",
       "2                    0              1                     0                 0   \n",
       "3                    0              0                     0                 0   \n",
       "4                    0              0                     0                 0   \n",
       "\n",
       "   Equipment_Wraps  Sex_F  Sex_M  \n",
       "0                1      1      0  \n",
       "1                1      1      0  \n",
       "2                0      1      0  \n",
       "3                1      1      0  \n",
       "4                1      1      0  \n",
       "\n",
       "[5 rows x 501 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Declare the StandardScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Scale the Age Column\n",
    "df['Age'] = scaler.fit_transform(df['Age'].values.reshape(-1, 1))\n",
    "\n",
    "# Scale the BodyweightKg Column\n",
    "df['BodyweightKg'] = scaler.fit_transform(df['BodyweightKg'].values.reshape(-1, 1))\n",
    "\n",
    "# Scale the Best3SquatKg Column\n",
    "df['Best3SquatKg'] = scaler.fit_transform(df['Best3SquatKg'].values.reshape(-1, 1))\n",
    "\n",
    "# Scale the Best3BenchKg Column\n",
    "df['Best3BenchKg'] = scaler.fit_transform(df['Best3BenchKg'].values.reshape(-1, 1))\n",
    "\n",
    "# Scale the Best3DeadliftKg Column\n",
    "df['Best3DeadliftKg'] = scaler.fit_transform(df['Best3DeadliftKg'].values.reshape(-1, 1))\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[.5 points] Divide your data into training and testing data using an 80% training and 20% testing split. Use the cross validation modules that are part of scikit-learn. Argue \"for\" or \"against\" splitting your data using an 80/20 split. That is, why is the 80/20 split appropriate (or not) for your dataset?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Using an 80/20 split makes sense, as we have a large dataset with a lot of features. We want to make sure that we have enough data to train our model, but we also want to make sure that we have enough data to test it as well. We don't want to overfit our model as a result of using too little data, so we will stick with the 80/20 split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the X and y values\n",
    "X = df.drop('WeightClassKg', axis=1)\n",
    "y = df['WeightClassKg']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using train_test_split from sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original shapes\n",
      "X: (68416, 501)\n",
      "y: (68416, 501)\n",
      "\n",
      "train shapes\n",
      "X: (54732, 500)\n",
      "y (54732,)\n",
      "\n",
      "test shapes\n",
      "X: (13684, 500)\n",
      "y: (13684,)\n"
     ]
    }
   ],
   "source": [
    "print('original shapes')\n",
    "print('X:', df.shape)\n",
    "print('y:', df.shape)\n",
    "print()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "\n",
    "print('train shapes')\n",
    "print('X:', X_train.shape)\n",
    "print('y', y_train.shape)\n",
    "print()\n",
    "\n",
    "print('test shapes')\n",
    "print('X:', X_test.shape)\n",
    "print('y:', y_test.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling (5 points total)\n",
    "The implementation of logistic regression must be written only from the examples given to you by the instructor. No credit will be assigned to teams that copy implementations from another source, regardless of if the code is properly cited. \n",
    "\n",
    "[2 points] Create a custom, one-versus-all logistic regression classifier using numpy and scipy to optimize. Use object oriented conventions identical to scikit-learn. You should start with the template developed by the instructor in the course. You should add the following functionality to the logistic regression classifier:\n",
    "\n",
    "* Ability to choose optimization technique when class is instantiated: either steepest ascent, stochastic gradient ascent, and {Newton's method/Quasi Newton methods}. \n",
    "* Update the gradient calculation to include a customizable regularization term (either using no regularization, L1 regularization, L2 regularization, or both L1 and L2 regularization). Associate a cost with the regularization term, \"C\", that can be adjusted when the class is instantiated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "\"\"\"\n",
    "@Params:\n",
    "    learning_rate: The learning rate for the model\n",
    "    n_iters: The number of iterations to run the model\n",
    "    type: The type of model to run, either 'stochastic_gradient_descent', 'newton', or 'steepest_ascent'\n",
    "    cost: variable cost for the model\n",
    "    method: The method to use for the model, either 'ovr' or 'ovo'. OVR is one vs rest, OVO is one vs one\n",
    "\"\"\"\n",
    "class LRC:\n",
    "    def __init__(self, learning_rate=0.01, n_iters=1000, type='stochastic_gradient_descent', cost=0, method='ovr'):\n",
    "        self.lr = learning_rate\n",
    "        # Number of iterations is initially 1000\n",
    "        self.n_iters = n_iters\n",
    "        # The weights will be made later as well as the bias, whenever we fit\n",
    "        self.weights = []\n",
    "        self.bias = []\n",
    "        self.colNames = []\n",
    "        self.type = type\n",
    "        self.binary_encoder_num = 0\n",
    "        self.cost = cost\n",
    "        self.method = method\n",
    "\n",
    "    \"\"\"\n",
    "    Fit function.\n",
    "    X: The feature matrix\n",
    "    y: The target vector\n",
    "    \"\"\"\n",
    "    def fit(self, X, y):\n",
    "      if self.method == 'ovr':\n",
    "        # Split the y data to be one hot encoded\n",
    "        y_df = pd.DataFrame(y)\n",
    "        one_hot_ys = []\n",
    "        # One hot encode the y\n",
    "        y_df = pd.get_dummies(y_df)\n",
    "        y_df_colNames = y_df.columns\n",
    "        self.colNames = y_df_colNames\n",
    "\n",
    "        for col in y_df_colNames:\n",
    "          one_hot_ys.append(y_df[col])\n",
    "\n",
    "        for this_y in one_hot_ys:\n",
    "          if self.type == 'stochastic_gradient_descent':\n",
    "            w, b = self.stochastic_gradient_descent(X, this_y)\n",
    "            self.weights.append(w)\n",
    "            self.bias.append(b)\n",
    "\n",
    "          elif self.type == 'newton':\n",
    "            w, b = self.newton_method(X, this_y)\n",
    "            self.weights.append(w)\n",
    "            self.bias.append(b)\n",
    "\n",
    "          elif self.type == 'steepest_ascent':\n",
    "            w, b = self.steepest_ascent(X, this_y)\n",
    "            self.weights.append(w)\n",
    "            self.bias.append(b)\n",
    "\n",
    "          else:\n",
    "            print('Invalid algorithm')\n",
    "            return\n",
    "\n",
    "          self.binary_encoder_num += 1\n",
    "\n",
    "      elif self.method == 'ovo':\n",
    "        # Split the y data\n",
    "        y_df = pd.DataFrame(y)\n",
    "\n",
    "        ys_to_classify = []\n",
    "        xs_for_classify = []\n",
    "\n",
    "        # One hot encode the y\n",
    "        y_df = pd.get_dummies(y_df)\n",
    "\n",
    "        # Get target vectors for each class against each other\n",
    "        for i in range(len(y_df.columns)):\n",
    "           for j in range(i + 1, len(y_df.columns)):\n",
    "              if i != j:\n",
    "                sub_x = X.copy()\n",
    "                self.colNames.append(y_df.columns[i] + '|' + y_df.columns[j])\n",
    "                # Make a new target vector where 1 is the ith class and 0 is the jth class\n",
    "                new_y = y_df[y_df.columns[i]] - y_df[y_df.columns[j]]\n",
    "\n",
    "                # Remove all the rows that are 0 both in new_y and from sub_x\n",
    "                sub_x = sub_x[new_y != 0]\n",
    "                new_y = new_y[new_y != 0]\n",
    "\n",
    "                # Replace all the -1s with 0s\n",
    "                new_y = new_y.replace(-1, 0)\n",
    "                # Add the new y to the list of y's to classify\n",
    "                ys_to_classify.append(new_y)\n",
    "                xs_for_classify.append(sub_x)\n",
    "\n",
    "        for this_y, this_X in zip(ys_to_classify, xs_for_classify):\n",
    "          if self.type == 'stochastic_gradient_descent':\n",
    "            print(\"shapes: \", this_X.shape, this_y.shape)\n",
    "            w, b = self.stochastic_gradient_descent(this_X, this_y)\n",
    "            self.weights.append(w)\n",
    "            self.bias.append(b)\n",
    "\n",
    "          elif self.type == 'newton':\n",
    "            w, b = self.newton_method(this_X, this_y)\n",
    "            self.weights.append(w)\n",
    "            self.bias.append(b)\n",
    "\n",
    "          elif self.type == 'steepest_ascent':\n",
    "            w, b = self.steepest_ascent(this_X, this_y)\n",
    "            self.weights.append(w)\n",
    "            self.bias.append(b)\n",
    "\n",
    "          else:\n",
    "            print('Invalid algorithm')\n",
    "            return\n",
    "\n",
    "          self.binary_encoder_num += 1\n",
    "\n",
    "    # Basic sigmoid function found online:\n",
    "    # https://en.wikipedia.org/wiki/Sigmoid_function\n",
    "    def sigmoid(self, x):\n",
    "        return 1 / (1 + np.exp(-x))\n",
    "\n",
    "    def basicLoss(self, y, y_pred):\n",
    "       return (y_pred - y)\n",
    "\n",
    "    # Calculate the difference between the predicted and actual values for the loss function\n",
    "    def calcLoss(self, y, y_pred):\n",
    "        return self.basicLoss(y, y_pred)\n",
    "\n",
    "    def calcGradient(self, X, y, weights, bias):\n",
    "       ydiff = y - self.predict_y(X, weights, bias).ravel()\n",
    "       gradient = np.mean(X * ydiff[:, np.newaxis], axis=0)\n",
    "\n",
    "       gradient = gradient.reshape(weights.shape)\n",
    "       # Add the regularization\n",
    "       gradient[:] += -2 * weights[:] * self.cost\n",
    "\n",
    "       return gradient, ydiff\n",
    "\n",
    "    def calcHessianGradient(self, X, y, weights, bias):\n",
    "      g = self.predict_y(X, weights, bias).ravel()\n",
    "\n",
    "      hessian = X.T @ np.diag(g * (1 - g)) @ X - 2 * self.cost\n",
    "\n",
    "      ydiff = y - g\n",
    "\n",
    "      gradient = np.sum(X * ydiff[:, np.newaxis], axis=0)\n",
    "      gradient = gradient.reshape(weights.shape)\n",
    "\n",
    "      # Add the regularization\n",
    "      gradient[:] += -2 * weights[:] * self.cost\n",
    "\n",
    "      return pinv(hessian) @ gradient, ydiff\n",
    "\n",
    "    def predict_y(self, X, weights, bias):\n",
    "       return self.sigmoid(X @ (weights + bias))\n",
    "\n",
    "    def newton_method(self, X, y):\n",
    "      # Make sure X and y are numpy arrays\n",
    "      X = np.array(X)\n",
    "      y = np.array(y)\n",
    "      \n",
    "      n_samples, n_features = X.shape\n",
    "\n",
    "      these_weights = np.zeros(n_features)\n",
    "      this_bias = 0\n",
    "\n",
    "      for i in range(self.n_iters):\n",
    "          clear_output(wait=True)\n",
    "          print(\"encoderNum: \", self.binary_encoder_num + 1)\n",
    "          print(\"iter: \", i)\n",
    "\n",
    "          gradient, loss = self.calcHessianGradient(X, y, these_weights, this_bias)\n",
    "\n",
    "          # Calculate the gradient of the bias\n",
    "          db = (1 / n_samples) * np.sum(loss)\n",
    "\n",
    "          # Update the weights and bias\n",
    "          these_weights += self.lr * (gradient)\n",
    "          this_bias += self.lr * db\n",
    "\n",
    "      clear_output(wait=True)\n",
    "\n",
    "      return these_weights, this_bias\n",
    "      \n",
    "    def stochastic_gradient_descent(self, X, y):\n",
    "      # Make sure X and y are numpy arrays\n",
    "      X = np.array(X)\n",
    "      y = np.array(y)\n",
    "      \n",
    "      n_samples, n_features = X.shape\n",
    "\n",
    "      these_weights = np.zeros(n_features)\n",
    "      this_bias = 0\n",
    "      \n",
    "      for i in range(self.n_iters):\n",
    "          if (i % 1000 == 0):\n",
    "            clear_output(wait=True)\n",
    "            print(\"encoderNum: \", self.binary_encoder_num + 1)\n",
    "            print(\"iter: \", i)\n",
    "\n",
    "          # Get a random sample from the X and y\n",
    "          random_index = np.random.randint(0, n_samples)\n",
    "          X_sample = X[random_index]\n",
    "          y_sample = y[random_index]\n",
    "\n",
    "          gradient, loss = self.calcGradient(X_sample, y_sample, these_weights, this_bias)\n",
    "\n",
    "          # Calculate the gradient of the bias\n",
    "          db = (1 / n_samples) * np.sum(loss)\n",
    "\n",
    "          # Update the weights and bias\n",
    "          these_weights += self.lr * (gradient)\n",
    "          this_bias += self.lr * db\n",
    "\n",
    "      clear_output(wait=True)\n",
    "        \n",
    "      return these_weights, this_bias\n",
    "    \n",
    "    def steepest_ascent(self, X, y):\n",
    "        # Make sure X and y are numpy arrays\n",
    "        X = np.array(X)\n",
    "        y = np.array(y)\n",
    "\n",
    "        n_samples, n_features = X.shape\n",
    "\n",
    "        these_weights = np.zeros(n_features)\n",
    "        this_bias = 0\n",
    "        \n",
    "        for i in range(self.n_iters):\n",
    "            if (i % 2 == 0):\n",
    "              clear_output(wait=True)\n",
    "              print(\"encoderNum: \", self.binary_encoder_num + 1)\n",
    "              print(\"iter: \", i)\n",
    "\n",
    "            gradient, loss = self.calcGradient(X, y, these_weights, this_bias)\n",
    "\n",
    "            db = (1 / n_samples) * np.sum(loss)\n",
    "            \n",
    "            these_weights += self.lr * (gradient)\n",
    "            this_bias += self.lr * db\n",
    "        \n",
    "        clear_output(wait=True)\n",
    "\n",
    "        return these_weights, this_bias\n",
    "\n",
    "    def predict(self, X):\n",
    "\n",
    "        # Get the list of linear models to be used to predict the y values\n",
    "        y_predicteds = []\n",
    "        for w, b in zip(self.weights, self.bias):\n",
    "          y_predicteds.append(self.predict_y(X, w, b))\n",
    "\n",
    "        # Convert the list of y_predicteds to a numpy array\n",
    "        y_predicteds = np.array(y_predicteds)\n",
    "\n",
    "        # Create the list to be returned\n",
    "        return_y = []\n",
    "\n",
    "        if self.method == 'ovr':\n",
    "          # Loop over each row of the y_predicteds\n",
    "          for i in range(len(y_predicteds[0])):\n",
    "            largest_index = 0\n",
    "            largest_value = 0\n",
    "\n",
    "            # Find the largest value in the row. Each column represents a class\n",
    "            for j in range(len(y_predicteds)):\n",
    "              if y_predicteds[j][i] > largest_value:\n",
    "                largest_index = j\n",
    "                largest_value = y_predicteds[j][i]\n",
    "\n",
    "            # Add that class name to the return_y list\n",
    "            return_y.append(self.colNames[largest_index].split('_')[1])\n",
    "\n",
    "        elif self.method == 'ovo':\n",
    "          colLen = len(y_predicteds[0])\n",
    "          # Loop over each column of the y_predicteds\n",
    "          for i in range(colLen):\n",
    "            # Loop over each row of the y_predicteds\n",
    "            for j in range(len(y_predicteds)):\n",
    "              colLen = len(y_predicteds[j])\n",
    "              # Make a dict of the possible classes\n",
    "              classes = {}\n",
    "              for col in self.colNames:\n",
    "                possibles = col.split('|')\n",
    "                classes[possibles[0]] = 0\n",
    "                classes[possibles[1]] = 0\n",
    "\n",
    "              class1 = self.colNames[j].split('|')[0]\n",
    "              class2 = self.colNames[j].split('|')[1]\n",
    "\n",
    "              # If the prediction is greater than 0.5, then the class is class1 predicted. class1 gets a point\n",
    "              if y_predicteds[j][i] > 0.5:\n",
    "                classes[class1] += 1\n",
    "\n",
    "              # If the prediction is less than 0.5, then the class is class2 predicted. class2 gets a point\n",
    "              else:\n",
    "                classes[class2] += 1\n",
    "                \n",
    "              # Find the class with the most points\n",
    "              largest_class = ''\n",
    "              largest_value = 0\n",
    "              for key, value in classes.items():\n",
    "                if value >= largest_value:\n",
    "                  largest_class = key\n",
    "                  largest_value = value\n",
    "\n",
    "            return_y.append(largest_class.split('_')[1])\n",
    "\n",
    "        return return_y\n",
    "\n",
    "    def accuracy(self, y_true, y_pred):\n",
    "        return np.sum(y_true == y_pred) / len(y_true)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running the classifiers"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[1.5 points] Train your classifier to achieve good generalization performance. That is, adjust the optimization technique and the value of the regularization term(s) \"C\" to achieve the best performance on your test set. Visualize the performance of the classifier versus the parameters you investigated. Is your method of selecting parameters justified? That is, do you think there is any \"data snooping\" involved with this method of selecting parameters?\n",
    "\n",
    "<span style=\"color: green\"> need to add more analysis for each of the classifiers, as well as more visualizations</span>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running Steepest Ascent\n",
    "* For this classifier, we set the number of iterations to 100, because it takes a moderate amount of time to calculate that many iterations, since we are doing operations on the whole dataset each time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average accuracy:  0.640382928968138\n"
     ]
    }
   ],
   "source": [
    "avg1 = 0\n",
    "\n",
    "for i in range(3):\n",
    "  classifier1 = LRC(learning_rate=0.01, n_iters=100, type='steepest_ascent', cost=0.1)\n",
    "  classifier1.fit(X_train, y_train)\n",
    "  predictions1 = classifier1.predict(X_test)\n",
    "  avg1 += classifier1.accuracy(y_test, predictions1)\n",
    "\n",
    "print(\"Average accuracy: \", avg1 / 3)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running stochastic gradient descent\n",
    "* For this method, we used the number of iterations as 10000, since it trains at an extremely fast rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average accuracy:  0.7135121309558607\n"
     ]
    }
   ],
   "source": [
    "avg2 = 0\n",
    "\n",
    "for i in range(10):\n",
    "  classifier2 = LRC(learning_rate=0.0001, n_iters=10000, type='stochastic_gradient_descent', cost=1)\n",
    "  classifier2.fit(X_train, y_train)\n",
    "  predictions2 = classifier2.predict(X_test)\n",
    "  avg2 += classifier2.accuracy(y_test, predictions2)\n",
    "\n",
    "print(\"Average accuracy: \", avg2 / 10)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running Newtons Method\n",
    "* For this method, the number of iterations is set to 4, since there are very few iterations needed to get a good result. Its pretty slow though, since it has to calculate the inverse of the hessian matrix each time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:  0.6016515638702133\n"
     ]
    }
   ],
   "source": [
    "classifier3 = LRC(learning_rate=.0001, n_iters=2, type='newton', cost=1)\n",
    "classifier3.fit(X_train, y_train)\n",
    "predictions3 = classifier3.predict(X_test)\n",
    "print(\"accuracy: \", classifier3.accuracy(y_test, predictions3))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[1.5 points] Compare the performance of your \"best\" logistic regression optimization procedure to the procedure used in scikit-learn. Visualize the performance differences in terms of training time and classification performance. Discuss the results. \n",
    "\n",
    "\n",
    "<span style=\"color: green;\"> Need to Do visualizations and discuss results </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our best linear regression procedure was stochastic gradient descent. It was both the fastest and the most accurate, taking an average of 1:30 and an average accuracy of 71%. Let's compare it to scikit-learn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:  0.8789096755334698\n"
     ]
    }
   ],
   "source": [
    "# Run logistic regression from sklearn on the data\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Create the model\n",
    "model = SGDClassifier()\n",
    "\n",
    "# Fit the model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Get the predictions\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Clear the output warnings\n",
    "clear_output(wait=True)\n",
    "\n",
    "# Get the accuracy\n",
    "print(\"accuracy: \", accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deployment (1 points total)\n",
    "* Which implementation of logistic regression would you advise be used in a deployed machine learning model, your implementation or scikit-learn (or other third party)? Why?\n",
    "\n",
    "We are going to compare our three: steepest ascent, stochastic gradient descent, and Newton's method. In this essay. They each have their own strengths and weaknesses, but with our specific dataset, we've elected that the steepest ascent is probably the route to go for deployment.\n",
    "\n",
    "Our steepest ascent moves in the direction of the steepest gradient ascent, the direction that increases the objective function the most. This algorithm is known for its consistency in terms of speed and accuracy, This is probably one of our biggest upsides to deploying it. When something is deployed and the devs are hands off for that instance, you don't want it to take forever, but you also want some form of reliability to it. While, it can be slow in certain circumstances, especially in our case where we have a lot of classes to classify, it seems to be the most reliable.\n",
    "\n",
    "Our stochastic gradient descent uses random samples to update the model parameters. This model is usally known for its speed, as it can quickly converge to a solution, but from our observation, it can be a little inconsistent, and we think we'd sacrifice a little time for accuracy. We think this would be our choice if our dataset was simply way too large to run the other options.\n",
    "\n",
    "Our Newton's method uses the second derivative of the function to find the minimum. This algorithm is known for its accuracy, as it can converge to the optimal solution quickly. However, with all our classes, this method takes a considerably more amount of time to converge onto an answer. This is combated with the common, high accuracy we observed. While this is nice, with our use case being weight class estimation, we felt we could sacrifice some of this accuracy for the sake of time.\n",
    "\n",
    "All three of these approaces has their own strengths and weaknesses. Steepest ascent is consistent in terms of speed and accuracy, while stochastic gradient descent is faster but less consistent. Newton's method is considerably accurate, but slow. The approach should depend on the specific problem at hand, and definitely the size of the dataset, and the desired level of accuracy. While considering these factors, we think the Steepest Ascent has the best intersection of speed and accuracy with our number of classes to be a good option for deployment"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exceptional Work (1 points total)\n",
    "* You have free reign to provide additional analyses. One idea: Update the code to use either \"one-versus-all\" or \"one-versus-one\" extensions of binary to multi-class classification. \n",
    "\n",
    "\n",
    "<span style=\"color: green\" >Need to make some analysis on the difference between ovo and ovr</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:  0.36765565624086527\n"
     ]
    }
   ],
   "source": [
    "# ovo testing\n",
    "classifier = LRC(learning_rate=.01, n_iters=100, type='steepest_ascent', cost=0.1, method='ovo')\n",
    "classifier.fit(X_train, y_train)\n",
    "predictions = classifier.predict(X_test)\n",
    "\n",
    "# Clear the output warnings\n",
    "clear_output(wait=True)\n",
    "\n",
    "print(\"accuracy: \", classifier.accuracy(y_test, predictions))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "38cca0c38332a56087b24af0bc80247f4fced29cb4f7f437d91dc159adec9c4e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
